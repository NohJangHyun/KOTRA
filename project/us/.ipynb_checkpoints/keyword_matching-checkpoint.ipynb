{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7143576",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0xbf in position 2: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamerica_2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp949\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df_keyword \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m미국_번역_전처리.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1236\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:633\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xbf in position 2: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"america_2.csv\", encoding = 'cp949')\n",
    "df_keyword = pd.read_csv(\"미국_번역_전처리.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c0af3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a8343c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LNG (liquid natural gas)', 'Bitum', 'iron mine', 'beef', 'Copper mine', 'crude oil', 'gold', 'Zinc', 'hard coal', 'Metal minerals', 'Aluminum', 'Raw', 'wheat', 'Nickel', 'butane', 'Propane', 'lamb', 'feed', 'naphtha', 'Nickel', 'Scrap metal', 'Non -gold', 'salt', 'Pigment', 'Dong Scrap', 'Seed', 'Royal Jerry', 'ammonia', 'Solid wood', 'Gratitude', 'Automotive Parts', 'rice', 'Chisis', 'meat', 'barley', 'medicine', 'weaponry', 'Plantic maintenance', 'wine', 'cosmetics', 'Non -ferrous metal products', 'Dynamic', 'corn', 'Aluminum', 'potato', 'Uji', 'Powdered milk', 'Cleansing supplies', 'Barley powder', 'Pak', 'noodle', 'Construction heavy equipment parts', 'Dairy', 'nuts', 'Medical electronics', 'grape', 'Rhyme', 'perfume', 'Cardboard', 'HDD', 'Chocolate', 'Medical container parts', 'Pisces', 'Pork', 'beverage', 'notice', 'Fine chemicals', 'fate', 'Industrial machinery', 'Medical container', 'Liquid pump', 'Meat', 'butter', 'Grain', 'benzene', 'Metal', 'Aluminum', 'Chae Yu -jong room', 'milk', 'Etc', 'Agricultural', 'mainstream', 'machinery', 'Plastic', 'molasses', 'Glass crafts', 'Weapon parts', 'Fiber', 'Maintenance', 'Fruit juice', 'Fishery', 'Paper product', 'measuring instrument', 'cast iron', 'Fine chemicals', 'Sauce', 'microphone', 'Printing paper', 'Yon Scrap', 'lubricant', 'Heating and heating machine', 'candy', 'honey', 'Portable computer', 'Haircut', 'Kraft magazine', 'Protein', 'Zinc', 'Chemical', 'coffee', 'Pump part', 'shrimp', 'Railway vehicle', 'flour', 'Machine parts', 'Analytical tester parts', 'cosmetics', 'Livestock meat', 'Two', 'Synthetic resin', 'glue', 'Chemical', 'Grain', 'chicken', 'Sanctions', 'shoes', 'Computer parts', 'Rubber product', 'Sportswear', 'Physics', 'Steel', 'Wooden', 'Medical hygiene', 'Plastic tube', 'bread', 'Bakery', 'Electronic application', 'Ice', 'Seafood', 'Oral and dentist hygiene products', 'coinage', 'Shaving', 'Blindness', 'Ethylene polymer', 'Phrases', 'Industrial machine', 'noodles', 'Polymethane acrylic acid methyl', 'Human body deodorant', 'Mobilization', 'tire', 'Household electronic components', 'Gas pump', 'Surface active agent', 'Pulmonary battery', 'Ya -up', 'Animal bone', 'Shiitake mushrooms', 'varnish', 'Wood', 'Glass', 'biscuit', 'Color galvanity steel sheet', 'Vegetable juice', 'Nitrogen fertilization', 'valve', 'Cowhide', 'Food machinery', 'Generator', 'Iron structure', 'Coffee preparation', 'Mattress', 'Personal computer', 'Agreement', 'Aluminum scrap', 'sausage', 'Complex fertilizer', 'china clay', 'toy', 'Woodworker', 'Steel dining table supplies and kitchen utensils', 'water', 'sweater', 'Metal machine tool part', 'Flow pressure system', 'peanut', 'Radiator', 'X -rays and radiation devices', 'Steel Metal Products', 'Yeast', 'books', 'Melting', 'Semiconductor', 'sugars', 'Motorboat', 'Household electronics', 'cherry', 'slush', 'eel', 'tuna', 'Construction heavy equipment', 'ship', 'Covenant', 'Connecting parts', 'Livestock', 'Low density ethylene', 'Mechanical element', 'Flamies', 'Jumble', 'Dishwasher', 'vegetable', 'Orange', 'Transportation machine', 'what', 'Plant', 'Stop', 'dress', 'Vehicle suspect', 'Tent and camp supplies', 'Cocoa', 'Tapping tool', 'Circuit protection container', 'Land surveyor', 'Non-woven', 'Hand tool', 'Electric axis and gear', 'Weightometer', 'Writing instrument', 'Fishery', 'dyes', 'Insulation code set', 'black tea', 'Polyester resin', 'Foamed', 'LCD', 'Rubber plastic processing machine', 'Bath product', 'Aluminum', 'Petrochemical', 'Mushroom', 'Sukam tool', 'Balloon', 'sensor', 'prints', 'Bedding', 'Skiing', 'Silicone resin', 'X -ray and radiation device parts', 'furniture', 'Container', 'bag', 'hat', 'Rubber plastic processing machine parts', 'Instrument', 'Automatic controller', 'Sound equipment parts', 'Battleship', 'DC generator', 'Key', 'Glass container', 'Iron and Non -Gold Gangbonggang', 'Shadow', 'Heating', 'Lighting equipment', 'Sports', 'Laser printer', 'Chemical', 'Big head', 'Gloves', 'Fixed food', 'Optical', 'Land price', 'Imitation', 'OLED', 'Undershirt', 'Brown', 'Female pants skirt', 'Computer', 'Household goods', 'fan', 'soap', 'Data Display device', 'bulb', 'Battery', 'Entertainment', 'breaker', 'Low pressure switch', 'Male shirt', 'Vacuum cleaner', 'Photographer', 'volt', 'nut', 'Contact lens', 'Gurije kitchenware', 'Copper', 'Fire alarm', 'Optical', 'Infant clothing', 'Individual device semiconductor', 'Transport and unloading machine parts', 'Traffic signal', 'Basic oil', 'Nickel', 'sugarcane', 'Air control part', 'printer', 'Expressway steel and ultra -light tools', 'Motor', 'Electronic instrument', 'Gentleman', 'DC motor', 'Self -dining table', 'Self -kitchenware', 'Integrated circuit semiconductor', 'Measurement tool', 'Harvesting machine', 'knife', 'valve', 'Printed circuit', 'antenna', 'Air pressure tool', 'Land surveyor', 'Mineral process', 'cabbage', 'tomato', 'Aircraft parts', 'Computer peripheral', 'Yuri Springb', 'car', 'Medical electromagnetic parts', 'Canned', 'Unprecedented film', 'Handkerchief', 'doll', 'Female', 'Cosmetics', 'Fixed meal', 'Vegetable', 'Wax', 'Two -wheeled car parts', 'Precious metal food', 'Spacecraft', 'Amount - say', 'Bicycle', 'Controller', 'process', 'Shipment', 'Dongguan connection detention', 'Sea lacquer', 'parachute', 'inverter', 'Male pants', 'fruit', 'refrigerator', 'worker bee', 'Electronic application device parts', 'Napkin', 'Electronic game console', 'Semiconductor equipment parts', 'Knitting', 'Household', 'Indoor', 'watch', 'garden truck', 'panties', 'Metamorphosis', 'accessories', 'Agricultural machinery', 'Golf', 'Mineral processing machine', 'Drink base', 'velvet', 'Motor', 'Plant', 'Prefabricated', 'River', 'glasses', 'Glass', 'Glass dish', 'Low pressure cable', 'Milling tool', 'Mine', 'Synthetic resin bag', 'Sports', 'Seed', 'wallpaper', 'Rail portion', 'Puzuz', 'Leather bag', 'bearing', 'Craft', 'Conversion device', 'Art', 'Blanket', 'Traveler', 'Engine combined power set', 'watch', 'car', 'pants', 'skirt', 'Copper', 'Etc', 'Aluminum container', 'Diamond tool', 'Flora', 'beer', 'Rubber clothing', 'Maddation', 'Memory semiconductor', 'Pottery kitchenware', 'Pottery', 'speaker', 'Livestock', 'blouse', 'bicycle', 'Automotive', 'Small motor', 'Material tester', 'dress', 'Optical lens', 'adhesive plaster', 'relay', 'Communication line', 'Alloy', 'VCR', 'Wood processing machine parts', 'Fabric', 'seaplane', 'Wired communication', 'Wire harness', 'Mining machine', 'Office weapon', 'Cutting tool', 'Spectacle frame', 'pliers', 'umbrella', 'Alarm signal', 'belt', 'Gloves', 'Textile processing machine parts', 'Leather processing machine parts', 'ballast', 'component', 'Office Supplies', 'stroller', 'tile', 'ceramic', 'press', 'Silicon wafer', 'Sportswear', 'Aluminum', 'Packaging', 'Fishing ball', 'welding machine', 'Air conditioner', 'Welding', 'Wireless repeater', 'thermometer', 'Electric steel sheet', 'Knitting', 'Agricultural machine', 'Food processing machine parts', 'Heating and heating equipment parts', 'Motherboard', 'cork', 'Suits', 'High -voltage cable', 'glasses', 'clothing', 'Hair dryer', 'leather', 'Songmill', 'Glass kitchenware', 'Glass', 'Clock line', 'Nickel nickel', 'Wireless remote control', 'Coal', 'Baby clothes', 'Warm container', 'Microwave', 'scissors', 'Food packaging machine', 'Gas alarm', 'My room clothes', 'Radio cassette', 'Clothing', 'necktie', 'Fabrication', 'carpet', 'Pajamas', 'Revolutionary clothing', 'chair', 'Dry transformer', 'Instrument', 'Electronic prefecture microscopic parts', 'mouse', 'Radar', 'wind', 'Union', 'instrument', 'rope', 'Power pack', 'wind', 'speedometer', 'whiskey', 'Clock part', 'Food packaging machine parts', 'Rubber', 'File', 'Coating', 'Badminton', 'Tennis', 'knife', 'Festival', 'Glossy', 'paper towel', 'copy', 'Iron instructor', 'Non -alloy instructor chain', 'Plating steel', 'Wooden ornament box', 'Cathode', 'Canned fish', 'Stainless steel pipe', 'camera', 'adapter', 'mixer', 'green tea', 'pesticide', 'Exercise gloves', 'Glass processing machine', 'scanner', 'electric rice cooker', 'Drilling tool', 'bandage', 'Nickel light', 'coat', 'jacket', 'Senate and', 'paper towel', 'piano', 'battery', 'Electronic parts', 'Polishing product', 'Curry', 'Shoe', 'curtain', 'Agar', 'mustard', 'Castreo', 'party', 'menswear', 'seaweed', 'Table tennis', 'shoes', 'radio', 'brandy', 'coconut', 'Wood household goods', 'Spice', 'bed', 'Accelerator', 'lighter', 'transistor', 'spring', 'Grain', 'Electromagnet', 'Electrical parts', 'Pajamas', 'Portable', 'Amazine', 'Shaving', 'fork', 'almond', 'Mayones', 'Rubber belt', 'Fur clothing', 'Supplement', 'Artificial fiber', 'Steel', 'Hodo', 'Refrigerator', 'Clock', 'Judezawa', 'Sea algae', 'wind', 'Sunflower', 'pepper', 'Png', 'Power tool', 'Electric iron', 'Glass mirror', 'Portable radio cassette', 'Forest', 'wig', 'Power supply', 'Gold', 'Celestial instrument', 'Sesame oil', 'spoon', 'Wall clock', 'chopsticks', 'spanner', 'Leather', 'Raw', 'Blood pressure meter', 'tapioca', 'Kochujang', 'Fiber', 'banana', 'apricot', 'radish', 'ginger']\n"
     ]
    }
   ],
   "source": [
    "keyword = list(df_keyword[\"번역\"])\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4fb6c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_embedding = []\n",
    "\n",
    "for ele in keyword:\n",
    "    keyword_embedding.append(model.encode(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6cdd7ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not_necessary = [\"dress\", \"notice\", \"Others\", \"Other\", \"hat\", \"rice\", \"feed\", \"Agreement\"]\n",
    "# for index, row in df.iterrows():\n",
    "#     voca_list = []\n",
    "#     for voca_index, voca_row in df_keyword.iterrows():\n",
    "#         if str(row[\"text\"]).find(' '+voca_row[\"번역\"])>0 and voca_row[\"번역\"] not in not_necessary:\n",
    "#             voca_list.append(voca_row[\"번역\"])\n",
    "# #             p = re.compile(voca_row[\"번역\"])\n",
    "# #             result = p.findall(str(row[\"text\"]))\n",
    "# #         if result != []:\n",
    "# #             voca_list.append(result)\n",
    "# #     voca_list = sum(voca_list, [])\n",
    "#     if voca_list != []:\n",
    "#         print(index, set(voca_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a2181155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = df.loc[18][\"text\"].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212829ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedding = []\n",
    "doc_words = []\n",
    "for doc in list(df[\"text\"]):\n",
    "    result = []\n",
    "    doc = str(doc).replace(\"\\n\", \" \")\n",
    "    word_tokens = text_to_word_sequence(text)\n",
    "    word_tokens = [x for x in word_tokens if len(x)>2]\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "    result = [word.lower() for word in result]\n",
    "    doc_words.append(result)\n",
    "    doc_embedding.append(model.encode(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ed7cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어임베딩해서 키워드에 대한 벡터표현을 뽑아내서 유사도가 높은거뽑기 0.5이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3cdde052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "# word_tokens = text_to_word_sequence(text)\n",
    "# word_tokens = [x for x in word_tokens if len(x)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1d20d86c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yoona\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "245452e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        result.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "418eaecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australia’s', 'customs', 'service', 'australian', 'customs', 'notice', '2022', 'april', 'import', 'statistical', 'code', 'changes', 'australian', 'bureau', 'statistics', 'advised', 'april', '2022', 'new', 'import', 'statistical', 'codes', 'unit', 'quantities', 'commence', 'products', 'urea', 'toxins', 'certain', 'engineered', 'structural', 'timber', 'products', 'new', 'codes', 'unit', 'quantities', 'australian', 'harmonized', 'export', 'commodity', 'classification', 'ahecc', 'goods', 'commence', 'may', '2022', 'new', 'ahecc', 'import', 'statistical', 'codes', 'urea', 'products', 'april', '2022', 'new', 'import', 'statistical', 'codes', 'commence', 'urea', 'products', 'importers', 'required', 'enter', 'new', 'statistical', 'codes', 'goods', 'urea', 'classified', 'tariff', 'subheading', '102', 'new', 'statistical', 'codes', 'identify', 'fertilisers', 'urea', 'technical', 'grade', 'urea', 'diesel', 'exhaust', 'fluid', 'urea', 'products', 'may', '2022', 'new', 'ahecc', 'codes', 'commence', 'urea', 'products', 'exporters', 'must', 'use', 'new', 'codes', 'exporting', 'goods', 'reviously', 'classified', 'ahecc', '31021000', 'new', 'ahecc', 'import', 'statistical', 'codes', 'toxins', 'april', '2022', 'import', 'statistical', 'codes', 'commence', 'toxins', 'saxitoxin', 'ricin', 'tariff', 'subheading', '3002', 'tariff', 'classification', 'goods', 'changed', 'tariff', 'subheading', '3002', 'january', '2022', 'due', 'commencement', '2022', 'harmonized', 'commodity', 'description', 'coding', 'system', 'new', 'statistical', 'codes', 'ensure', 'statistics', 'toxins', 'corre', 'ctly', 'captured', 'new', 'ahecc', 'codes', 'saxitoxin', 'ricin', 'goods', 'previously', 'classified', 'ahecc', '30024900', 'commence', 'may', '2022', 'exporters', 'required', 'classify', 'goods', 'new', 'ahecc', 'codes', 'date', 'new', 'unit', 'quantities', 'ertain', 'engineered', 'structural', 'timber', 'products', 'unit', 'imported', 'glue', 'laminated', 'timber', 'cross', 'laminated', 'timber', 'beams', 'engineered', 'structural', 'timber', 'products', 'longer', '‘sm’', 'square', 'metres', 'april', '2022', 'unit', 'goods', 'specified', 'enable', 'alternative', 'measurements', 'used', 'import', 'goods', 'units', 'used', 'export', 'goods', 'change', 'square', 'metres', 'may', '2022', 'revised', 'tariff', 'working', 'pages', 'reflecting', 'changes', 'avail', 'able', 'attachment', 'enquiries', 'related', 'notice', 'directed', 'tradepolicy1', 'abf', 'gov', 'signed', 'kimberlee', 'stamatis', 'assistant', 'secretary', 'customs', 'trade', 'policy', 'branch', 'australian', 'border', 'force', 'march', '2022']\n"
     ]
    }
   ],
   "source": [
    "result = [word.lower() for word in result]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fffd1489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00932007,  0.01397385,  0.01140888, ..., -0.03080872,\n",
       "        -0.02245384, -0.02164312],\n",
       "       [-0.0142872 ,  0.00228825,  0.01971095, ...,  0.019541  ,\n",
       "         0.0178088 , -0.03983379],\n",
       "       [ 0.01065362,  0.01779893, -0.04340098, ...,  0.0505168 ,\n",
       "         0.0319691 , -0.01365004],\n",
       "       ...,\n",
       "       [ 0.00890926,  0.00684061,  0.01646895, ..., -0.00776284,\n",
       "        -0.05492141,  0.01674275],\n",
       "       [ 0.06159662, -0.0184765 , -0.12547065, ..., -0.06608905,\n",
       "        -0.02981977,  0.03235361],\n",
       "       [-0.03906596, -0.02388823, -0.04350491, ..., -0.03803896,\n",
       "        -0.01944329,  0.03048876]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding = model.encode(result)\n",
    "doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "234cd613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00932007,  0.01397385,  0.01140888, ..., -0.03080872,\n",
       "        -0.02245384, -0.02164312],\n",
       "       [-0.0142872 ,  0.00228825,  0.01971095, ...,  0.019541  ,\n",
       "         0.0178088 , -0.03983379],\n",
       "       [ 0.01065362,  0.01779893, -0.04340098, ...,  0.0505168 ,\n",
       "         0.0319691 , -0.01365004],\n",
       "       ...,\n",
       "       [ 0.00890926,  0.00684061,  0.01646895, ..., -0.00776284,\n",
       "        -0.05492141,  0.01674275],\n",
       "       [ 0.06159662, -0.0184765 , -0.12547065, ..., -0.06608905,\n",
       "        -0.02981977,  0.03235361],\n",
       "       [-0.03906596, -0.02388823, -0.04350491, ..., -0.03803896,\n",
       "        -0.01944329,  0.03048876]], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7816d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n"
     ]
    }
   ],
   "source": [
    "final_result = []\n",
    "# for doc in range(len(doc_embedding)):\n",
    "for i in range(len(doc_embedding)):\n",
    "    for j in range(len(keyword_embedding)):\n",
    "        distances = cosine_similarity([doc_embedding[i]], [keyword_embedding[j]])\n",
    "        if distances[0][0]>0.8:\n",
    "            final_result.append(result[i])\n",
    "# distances = cosine_similarity([doc_embedding[0]], candidate_embeddings)\n",
    "print(set(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "379e4aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [201]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(doc)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(keyword_embedding)):\n\u001b[1;32m----> 7\u001b[0m         distances \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeyword_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m distances[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.8\u001b[39m:\n\u001b[0;32m      9\u001b[0m             final_result\u001b[38;5;241m.\u001b[39mappend(result[i])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1253\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1253\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1255\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1792\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1792\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1800\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:821\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    815\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 821\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "doc_keywords = []\n",
    "for index, doc in enumerate(doc_embedding):\n",
    "    final_result = []\n",
    "    print(doc)\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([doc[i]], [keyword_embedding[j]])\n",
    "            if distances[0][0]>0.8:\n",
    "                final_result.append(doc_words[index][i])\n",
    "# distances = cosine_similarity([doc_embedding[0]], candidate_embeddings)\n",
    "    print(set(final_result))\n",
    "    doc_keywords.append(set(final_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
