{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7143576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"america_2.csv\")\n",
    "df_keyword = pd.read_csv(\"미국_번역_전처리.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7030598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>품목</th>\n",
       "      <th>번역</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>원유</td>\n",
       "      <td>crude oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LNG(액상천연가스)</td>\n",
       "      <td>LNG (liquid natural gas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>프로판</td>\n",
       "      <td>Propane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>반도체제조용장비</td>\n",
       "      <td>Semiconductor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>쇠고기</td>\n",
       "      <td>beef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           품목                        번역\n",
       "0           0           원유                 crude oil\n",
       "1           1  LNG(액상천연가스)  LNG (liquid natural gas)\n",
       "2           2          프로판                   Propane\n",
       "3           3     반도체제조용장비             Semiconductor\n",
       "4           4          쇠고기                      beef"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keyword.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0af3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8343c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crude oil', 'LNG (liquid natural gas)', 'Propane', 'Semiconductor', 'beef', 'airplane', 'Controller', 'process', 'medicine', 'Royal Jerry', 'naphtha', 'Flamies', 'Fine chemicals', 'butane', 'car', 'Aircraft engine', 'Big head', 'Petrochemical', 'Fine chemicals', 'feed', 'wheat', 'Pork', 'Dong Scrap', 'Electric car', 'Medical container', 'Alternator', 'Chemical', 'Optical', 'Scrap metal', 'Pak', 'Plastic', 'Bitum', 'Physics', 'dyes', 'Synthetic resin', 'Precious metal food', 'valve', 'Basic oil', 'Integrated circuit semiconductor', 'Personal computer', 'Orange', 'Chisis', 'mainstream', 'Metal minerals', 'machinery', 'Phrases', 'Electronic application', 'Instrument', 'Industrial machine', 'Compression', 'Optical', 'Automotive Parts', 'Medical electronics', 'cosmetics', 'measuring instrument', 'Precious metal food', 'Memory semiconductor', 'Polyamide resin', 'almond', 'Soybean oil', 'cast iron', 'Silicon wafer', 'Radar', 'notice', 'Protein', 'potato', 'Paper product', 'Mechanical element', 'platinum', 'Connecting parts', 'Automatic controller', 'Agricultural', 'Cowhide', 'noodle', 'Golf', 'Hodo', 'Turbo jet', 'Pump part', 'Liquid pump', 'coffee', 'Petroleum', 'pulp', 'Tile product', 'Pottery', 'Gas pump', 'Aluminum', 'Truck', 'rice', 'wine', 'Acrylonite Neil', 'Aircraft parts', 'Bolt and nut', 'Bunker-C Yu', 'Analytical tester parts', 'Container', 'Industrial machinery', 'Aluminum', 'Ya -up', 'Steel', 'Non -ferrous metal products', 'Optical lens', 'Glass', 'Wondering parts', 'Flow pressure system', 'Semiconductor equipment parts', 'weaponry', 'Stop', 'Pigment', 'Silicone resin', 'Insulation code set', 'X -ray and radiation device parts', 'Mobilization', 'Fishery', 'silver', 'River', 'Medical electromagnetic parts', 'Machine parts', 'fruit', 'Medical hygiene', 'varnish', 'Haircut', 'Plastic tube', 'Electronic instrument', 'Cocoa', 'Chemical', 'X -rays and radiation devices', 'Contact lens', 'Rubber product', 'lubricant', 'Zinc', 'bearing', 'Electric axis and gear', 'Passenger tire', 'Spacecraft', 'Glass mirror', 'LCD', 'books', 'pesticide', 'Battleship', 'Low pressure breaker', 'Low pressure switch', 'lemon', 'Flame ignition internal combustion engine', 'Air conditioner', 'Chae Yu -jong room', 'Fruit juice', 'Oral hygiene', 'Computer peripheral', 'Polycarbonate', 'Synthetic rubber', 'Air regulator', 'Non -gold', 'Steel Metal Products', 'Low density ethylene', 'Chocolate', 'Transport and unloading machine parts', 'Automatic controller', 'meat', 'Glossy', 'Household goods', 'Sports', 'Polymethane acrylic acid methyl', 'china clay', 'Computer', 'Glass processing machine', 'Compression', 'Acetate company', 'Sauce', 'Epoxy', 'sausage', 'sensor', 'Fiber', 'slush', 'Circuit protection container', 'bread', 'Computer parts', 'Motor', 'Insulation parts', 'Medical container parts', 'Surface active agent', 'shoes', 'Photographer', 'Seed', 'valve', 'Petrochemical', 'DC generator', 'Cleansing supplies', 'Sanctions', 'Steel kitchenware', 'Steel', 'Cardboard', 'perfume', 'Vegetable juice', 'Nickelpan and', 'Pesticide', 'Electron microscope', 'Construction heavy equipment', 'prints', 'sugars', 'rectifier', 'car', 'Sportswear', 'butter', 'Pisces', 'Acetate fiber', 'Land surveyor', 'Automotive', 'Yeast', 'Plating steel', 'Bakery', 'glue', 'Maintenance', 'Etc', 'transistor', 'Jumble', 'Nickel', 'Wireless', 'antenna', 'Glass kitchenware', 'Glass', 'Low pressure cable', 'biscuit', 'thermometer', 'Metal machine tool part', 'Plantic maintenance', 'HDD', 'White plate', 'Printed circuit', 'Heating part', 'Heating equipment parts', 'Stainless steel', 'vegetable', 'bulb', 'Dynamic', 'Office Supplies', 'nuts', 'Material tester', 'Motorcycle', 'Leafy', 'inverter', 'Compression point', 'corn', 'Ethylene polymer', 'Alarm signal', 'Construction heavy equipment parts', 'Bowling', 'Printing machine', 'Grain', 'Transportation machine', 'Powdered milk', 'Friction', 'mixer', 'Ice', 'Aluminum', 'beer', 'Non-woven', 'Chemical', 'Electronic prefecture microscopic parts', 'adhesive plaster', 'Polishing product', 'Ultrasound', 'Fishery', 'Dairy', 'High -voltage cable', 'Weapon parts', 'Grain', 'Metal', 'Coffee preparation', 'Acet', 'Solid wood', 'Polypropylene', 'Electronic parts', 'Special car', 'whiskey', 'paper towel', 'tomato', 'DC motor', 'Nickel tube', 'Fixed festival', 'Wax', 'peanut', 'Entertainment', 'Lighting equipment', 'component', 'Household electronic components', 'chicken', 'Steel', 'Endoscope', 'Engine combined power set', 'Bedding', 'toy', 'Traffic', 'Welding', 'glasses', 'diode', 'TV', 'Small motor', 'DC motor', 'Alternator', 'candy', 'Rubber', 'Chloride', 'Stainless and alloy steel bonggang', 'beverage', 'Coaxial cable', 'Aluminum scrap', 'Portable computer', 'Instrument', 'Plant', 'speaker', 'Writing instrument', 'Opening and closing', 'Nickel', 'Air control part', 'roe', 'turbulence', 'OLED', 'Other chairs', 'Railway vehicle', 'Expressway steel and ultra -light tools', 'bag', 'furniture', 'Cutting tool', 'cosmetics', 'gold', 'sweater', 'grape', 'Heating', 'Electrical parts', 'Electrical fold', 'Forest', 'lighter', 'Nylon', 'copper', 'Alarm signal', 'Shadow', 'Optical cable', 'Auxiliary memory device', 'plum', 'Copper', 'benzene', 'Aluminum structure', 'Fabrication', 'Mu -Gye Mokgang', 'chicken', 'Polyethylene Terephthalate film', 'seaplane', 'spring', 'Agricultural machinery', 'honey', 'Artificial fiber', 'mustard', 'Synthetic fiber', 'Agricultural machine', 'refrigerator', 'Conversion device', 'Helicopter', 'Radiator', 'Air conditioner', 'black smoke', 'Hot water', 'Motorboat', 'Sea lacquer', 'Fixed food', 'Hand tool', 'Drink base', 'instrument', 'word', 'Air pressure tool', 'Unprecedented film', 'Electromagnet', 'Prehistoric', 'Nickel', 'Fiber', 'Guitar', 'tire', 'Wire harness', 'Bath product', 'Metamorphosis', 'Aluminum', 'speedometer', 'Harvesting machine', 'Individual device semiconductor', 'Iron structure', 'Complex fertilizer', 'Steel', 'Mejo cigarette', 'Rubber plastic processing machine parts', 'Radiator', 'Synthetic resin bag', 'Dry transformer', 'String', 'Paper printing machine parts', 'worker bee', 'hat', 'Mineral process', 'Dae-gu', 'salt', 'microscope', 'kidney bean', 'relay', 'Aluminum container', 'Undershirt', 'Alloy river cold rolling steel plate', 'Self -dining table', 'Self -kitchenware', 'device', 'Nickel', 'Brown', 'Rolling machine', 'Broadcasting communication device', 'amplifier', 'Two -wheeled car parts', 'Food machinery', 'Stainless steel pipe', 'Shaving', 'Casting equipment', 'Household electronics', 'Bicycle', 'battery', 'Ship fireworks point', 'Wired communication', 'Generator', 'Spanning battery', 'Seafood', 'pliers', 'Kraft magazine', 'Fishery', 'Shaving', 'welding machine', 'Acrylonite Neil Butadi', 'Livestock', 'green gram', 'Agricultural', 'Polyamid Film', 'Aloninum tube connection', 'Distribution board', 'Nitrogen fertilization', 'Imitation', 'Aluminum tube', 'Fat', 'Food processing machine parts', 'Songmill', 'spanner', 'polystyrene', 'Wood', 'party', 'Festival', 'Two', 'Unlimited transfer device', 'Electroplania', 'fan', 'Ship compression point engine engine', 'Metamorphosis', 'High -pressure circuit connection', 'Sunflower', 'Copper wire', 'Sodium hydroxide', 'Fishing ball', 'Napkin', 'Mining machine', 'Skiing', 'Shrine', 'Individual device semiconductor parts', 'coinage', 'Food packaging machine', 'soap', 'bicycle', 'Casting equipment', 'microphone', 'Winding', 'Battery', 'Milling tool', 'Amount - say', 'Tent and camp supplies', 'Safety glass', 'watch', 'Glass container', 'rope', 'Power tool', 'Motherboard', 'water', 'Rubber plastic processing machine', 'Female pants skirt', 'Mollusk', 'Stainless steel', 'Male pants', 'Drilling tool', 'Ship', 'Measurement tool', 'Fabric', 'Vehicle suspect', 'Nickel', 'Food packaging machine parts', 'Nickel tube connection', 'Fire helper', 'squid', 'Electronic game console', 'Land surveyor', 'Data Display device', 'Tomato Keak', 'dress', 'Cherry', 'plate glass', 'Aircraft chair', 'Polyester resin', 'Propylene polymer', 'tool', 'Communication line', 'Etc', 'Steel and non -combined gold steel tobility (small and medium)', 'adapter', 'Danggang', 'Seed', 'Pearl', 'Aluminum', 'Cod roof', 'Mayones', 'Carbon parts', 'Butyl rubber', 'Pulmonary battery', 'Human body deodorant', 'Shoe', 'black tea', 'Art', 'flour', 'Aluminum', 'Foamed', 'Tungsten', 'Pollock', 'Rubber belt', 'Dragon', 'Wooden', 'Rubber clothing', 'Integrated circuit semiconductor parts', 'Breaker', 'Potassium', 'Cast iron consolidation', 'pants', 'skirt', 'Strawberry', 'wind', 'Periodical', 'fork lift', 'Aluminum line', 'Grain', 'Plastic pallets and walls', 'noodles', 'Propylene', 'tile', 'Revolutionary clothing', 'Optical glass', 'Agreement', 'Iron and Non -Gold River cold rolling steel plate', 'Boring tool', 'Heating equipment', 'onion', 'doll', 'Male shirt', 'pea', 'Dongje', 'Stainless steel plate', 'Inflow transformer', 'watch', 'Copper mine', 'shrimp', 'percussion instrument', 'Weightometer', 'Power supply', 'Sound equipment parts', 'milk', 'Variable resistance', 'Flora', 'SBR', 'Indoor', 'cucumber', 'VCR', 'Knitting', 'Cosmetics', 'Experimental practical electricity', 'Nickel scrap', 'Dairy', 'Celestial instrument', 'Vegetable', 'Electric steel sheet', 'Bus and cargo tires', 'Alloy', 'Handkerchief', 'knife', 'Marine structure', 'Variable', 'Reactor and parts', 'Dongguan connection detention', 'Puzuz', 'paper towel', 'Animal maintenance', 'Glass and intestinal food', 'Ginseng', 'High -voltage', 'High pressure breaker', 'Blood pressure meter', 'Electronic application device parts', 'curtain', 'Flamies', 'Vacuum cleaner', 'Knitting', 'Magnetic resonance shooter', 'camera', 'Electrocardiography', 'ballast', 'Female']\n"
     ]
    }
   ],
   "source": [
    "keyword = list(df_keyword[\"번역\"])\n",
    "print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb6c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_embedding = []\n",
    "\n",
    "for ele in keyword:\n",
    "    keyword_embedding.append(model.encode(ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c725a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl (444.0 MB)\n",
      "     -------------------------------------- 444.0/444.0 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     ---------------------------------------- 123.4/123.4 kB ? eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 11.2 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 1.7 MB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     -------------------------------------- 42.6/42.6 kB 521.6 kB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     ------------------------------------- 895.7/895.7 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 10.9 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     --------------------------------------- 14.2/14.2 MB 10.9 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "     -------------------------------------- 438.7/438.7 kB 9.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 9.3 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp39-cp39-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------- 232.4/232.4 kB 13.9 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.8/167.8 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\water\\anaconda3\\envs\\kotra\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.5/151.5 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=503c94b801c6b29b47adba72c9b58cbf24c0aa006069217180e8921efd951121\n",
      "  Stored in directory: c:\\users\\water\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, werkzeug, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, importlib-metadata, google-auth, markdown, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 h5py-3.7.0 importlib-metadata-4.12.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 werkzeug-2.2.1 wrapt-1.14.1 zipp-3.8.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdde052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d20d86c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\water\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212829ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문서 하나씩 줄 바꿈, 불용어 제거, 단어 별 자르기, \n",
    "doc_embedding = []\n",
    "doc_words = []\n",
    "for doc in list(df[\"first_page_text\"][:100]):\n",
    "    result = []\n",
    "    doc = str(doc).replace(\"\\n\", \" \")\n",
    "    word_tokens = text_to_word_sequence(doc)\n",
    "    word_tokens = [x for x in word_tokens if len(x)>2]\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            result.append(w)\n",
    "    result = [word.lower() for word in result]\n",
    "    doc_words.append(result)\n",
    "    doc_embedding.append(model.encode(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2ed7cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어임베딩해서 키워드에 대한 벡터표현을 뽑아내서 유사도가 높은거뽑기 0.5이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "245452e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        result.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "418eaecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['australia’s', 'customs', 'service', 'australian', 'customs', 'notice', '2022', 'april', 'import', 'statistical', 'code', 'changes', 'australian', 'bureau', 'statistics', 'advised', 'april', '2022', 'new', 'import', 'statistical', 'codes', 'unit', 'quantities', 'commence', 'products', 'urea', 'toxins', 'certain', 'engineered', 'structural', 'timber', 'products', 'new', 'codes', 'unit', 'quantities', 'australian', 'harmonized', 'export', 'commodity', 'classification', 'ahecc', 'goods', 'commence', 'may', '2022', 'new', 'ahecc', 'import', 'statistical', 'codes', 'urea', 'products', 'april', '2022', 'new', 'import', 'statistical', 'codes', 'commence', 'urea', 'products', 'importers', 'required', 'enter', 'new', 'statistical', 'codes', 'goods', 'urea', 'classified', 'tariff', 'subheading', '102', 'new', 'statistical', 'codes', 'identify', 'fertilisers', 'urea', 'technical', 'grade', 'urea', 'diesel', 'exhaust', 'fluid', 'urea', 'products', 'may', '2022', 'new', 'ahecc', 'codes', 'commence', 'urea', 'products', 'exporters', 'must', 'use', 'new', 'codes', 'exporting', 'goods', 'reviously', 'classified', 'ahecc', '31021000', 'new', 'ahecc', 'import', 'statistical', 'codes', 'toxins', 'april', '2022', 'import', 'statistical', 'codes', 'commence', 'toxins', 'saxitoxin', 'ricin', 'tariff', 'subheading', '3002', 'tariff', 'classification', 'goods', 'changed', 'tariff', 'subheading', '3002', 'january', '2022', 'due', 'commencement', '2022', 'harmonized', 'commodity', 'description', 'coding', 'system', 'new', 'statistical', 'codes', 'ensure', 'statistics', 'toxins', 'corre', 'ctly', 'captured', 'new', 'ahecc', 'codes', 'saxitoxin', 'ricin', 'goods', 'previously', 'classified', 'ahecc', '30024900', 'commence', 'may', '2022', 'exporters', 'required', 'classify', 'goods', 'new', 'ahecc', 'codes', 'date', 'new', 'unit', 'quantities', 'ertain', 'engineered', 'structural', 'timber', 'products', 'unit', 'imported', 'glue', 'laminated', 'timber', 'cross', 'laminated', 'timber', 'beams', 'engineered', 'structural', 'timber', 'products', 'longer', '‘sm’', 'square', 'metres', 'april', '2022', 'unit', 'goods', 'specified', 'enable', 'alternative', 'measurements', 'used', 'import', 'goods', 'units', 'used', 'export', 'goods', 'change', 'square', 'metres', 'may', '2022', 'revised', 'tariff', 'working', 'pages', 'reflecting', 'changes', 'avail', 'able', 'attachment', 'enquiries', 'related', 'notice', 'directed', 'tradepolicy1', 'abf', 'gov', 'signed', 'kimberlee', 'stamatis', 'assistant', 'secretary', 'customs', 'trade', 'policy', 'branch', 'australian', 'border', 'force', 'march', '2022']\n"
     ]
    }
   ],
   "source": [
    "result = [word.lower() for word in result]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fffd1489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00932007,  0.01397385,  0.01140888, ..., -0.03080872,\n",
       "        -0.02245384, -0.02164312],\n",
       "       [-0.0142872 ,  0.00228825,  0.01971095, ...,  0.019541  ,\n",
       "         0.0178088 , -0.03983379],\n",
       "       [ 0.01065362,  0.01779893, -0.04340098, ...,  0.0505168 ,\n",
       "         0.0319691 , -0.01365004],\n",
       "       ...,\n",
       "       [ 0.00890926,  0.00684061,  0.01646895, ..., -0.00776284,\n",
       "        -0.05492141,  0.01674275],\n",
       "       [ 0.06159662, -0.0184765 , -0.12547065, ..., -0.06608905,\n",
       "        -0.02981977,  0.03235361],\n",
       "       [-0.03906596, -0.02388823, -0.04350491, ..., -0.03803896,\n",
       "        -0.01944329,  0.03048876]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding = model.encode(result)\n",
    "doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "234cd613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00932007,  0.01397385,  0.01140888, ..., -0.03080872,\n",
       "        -0.02245384, -0.02164312],\n",
       "       [-0.0142872 ,  0.00228825,  0.01971095, ...,  0.019541  ,\n",
       "         0.0178088 , -0.03983379],\n",
       "       [ 0.01065362,  0.01779893, -0.04340098, ...,  0.0505168 ,\n",
       "         0.0319691 , -0.01365004],\n",
       "       ...,\n",
       "       [ 0.00890926,  0.00684061,  0.01646895, ..., -0.00776284,\n",
       "        -0.05492141,  0.01674275],\n",
       "       [ 0.06159662, -0.0184765 , -0.12547065, ..., -0.06608905,\n",
       "        -0.02981977,  0.03235361],\n",
       "       [-0.03906596, -0.02388823, -0.04350491, ..., -0.03803896,\n",
       "        -0.01944329,  0.03048876]], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7816d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n"
     ]
    }
   ],
   "source": [
    "final_result = []\n",
    "# for doc in range(len(doc_embedding)):\n",
    "for i in range(len(doc_embedding)):\n",
    "    for j in range(len(keyword_embedding)):\n",
    "        distances = cosine_similarity([doc_embedding[i]], [keyword_embedding[j]])\n",
    "        if distances[0][0]>0.8:\n",
    "            final_result.append(result[i])\n",
    "# distances = cosine_similarity([doc_embedding[0]], candidate_embeddings)\n",
    "print(set(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "379e4aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n",
      "{'ricin', 'measurements', 'ahecc', 'timber', 'notice', 'avail', 'glue', 'due', 'toxins', 'stamatis'}\n",
      "[[-0.00932007  0.01397385  0.01140888 ... -0.03080872 -0.02245384\n",
      "  -0.02164312]\n",
      " [-0.0142872   0.00228825  0.01971095 ...  0.019541    0.0178088\n",
      "  -0.03983379]\n",
      " [ 0.01065362  0.01779893 -0.04340098 ...  0.0505168   0.0319691\n",
      "  -0.01365004]\n",
      " ...\n",
      " [ 0.00890926  0.00684061  0.01646895 ... -0.00776284 -0.05492141\n",
      "   0.01674275]\n",
      " [ 0.06159662 -0.0184765  -0.12547065 ... -0.06608905 -0.02981977\n",
      "   0.03235361]\n",
      " [-0.03906596 -0.02388823 -0.04350491 ... -0.03803896 -0.01944329\n",
      "   0.03048876]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [201]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(doc)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(keyword_embedding)):\n\u001b[1;32m----> 7\u001b[0m         distances \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeyword_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m distances[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.8\u001b[39m:\n\u001b[0;32m      9\u001b[0m             final_result\u001b[38;5;241m.\u001b[39mappend(result[i])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1253\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1253\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1255\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1792\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1792\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1800\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:821\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    815\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m feature(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m a minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_features, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 821\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "doc_keywords = []\n",
    "for index, doc in enumerate(doc_embedding):\n",
    "    final_result = []\n",
    "    print(doc)\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([doc[i]], [keyword_embedding[j]])\n",
    "            if distances[0][0]>0.8:\n",
    "                final_result.append(doc_words[index][i])\n",
    "# distances = cosine_similarity([doc_embedding[0]], candidate_embeddings)\n",
    "    print(set(final_result))\n",
    "    doc_keywords.append(set(final_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
