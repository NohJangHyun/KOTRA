{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d316fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db2cf9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"호주_세관_v2(new20).csv\")\n",
    "\n",
    "df_title = list(df['title'])\n",
    "df_text = list(df['text'])\n",
    "df_add = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_add.append(df_title[i]+\"\"+df_text[i])\n",
    "\n",
    "df_keyword = pd.read_csv(\"호주_번역_100.csv\", index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28364226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "doc_bigram_keywords = []\n",
    "\n",
    "for doc in df_add[:10]:\n",
    "    #구두점 제거\n",
    "    doc1 = \"\".join([i for i in doc if i not in string.punctuation]).strip()\n",
    "\n",
    "    #숫자 제거\n",
    "    doc2 = \"\".join([i for i in doc1 if not i.isdigit()])\n",
    "\n",
    "    #월 제거\n",
    "    month = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august',\n",
    "            'september', 'october', 'november', 'december', 'jan', 'feb', 'mar', 'apr',\n",
    "             'may', 'jun','jul', 'aug', 'sep', 'oct', 'nov', 'dec']   \n",
    "    doc3 = \" \".join([i for i in doc2.split() if i not in month])\n",
    "    \n",
    "    #전처리한 문서에서 바이그램 추출 + 불용어 제거\n",
    "    n_gram_range = (2,2)\n",
    "    stop_words = \"english\"\n",
    "    count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc3])\n",
    "    candidates = count.get_feature_names_out() #바이그램\n",
    "\n",
    "    #전처리 X 문서와 전처리한 문서에서 추출한 키워드 수치화\n",
    "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "    doc_embedding = model.encode([doc]) #전체 문서\n",
    "    candidate_embeddings = model.encode(candidates)#추출한 bigram\n",
    "    \n",
    "    #문서와 가장 유사한 키워드 top 20 추출\n",
    "    top_n = 20\n",
    "    distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "    doc_bigram_keyword = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
    "    doc_bigram_keywords.append(doc_bigram_keyword)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60099866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 X 문서와 가장 유사한 키워드 벡터화\n",
    "doc_bigram_embeddings = []\n",
    "for keyword in doc_bigram_keywords:\n",
    "    doc_bigram_embedding = []\n",
    "    for word in keyword:\n",
    "        doc_bigram_embedding.append(model.encode(keyword))\n",
    "    doc_bigram_embeddings.append(doc_bigram_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a0a0c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "#키워드 임베딩\n",
    "keyword = list(df_keyword[\"번역\"])\n",
    "keyword_embedding = []\n",
    "\n",
    "for ele in keyword:\n",
    "    keyword_embedding.append(model.encode(ele))\n",
    "\n",
    "print(len(keyword_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8b83ce06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bigram)):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(keyword_embedding)):\n\u001b[1;32m---> 12\u001b[0m         distances \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbigram\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeyword_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m distances[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.75\u001b[39m:\n\u001b[0;32m     14\u001b[0m             bigram_result\u001b[38;5;241m.\u001b[39mappend(doc_bigram_keywords[index][i])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1351\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \n\u001b[0;32m   1319\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;124;03mkernel matrix : ndarray of shape (n_samples_X, n_samples_Y)\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1353\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    147\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    148\u001b[0m         X,\n\u001b[0;32m    149\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         Y,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KOTRA\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "#문서 키워드(doc_bigram_embedding)와 키워드 100(keyword_embedding) 유사도 비교 \n",
    "bigram_key_result = []\n",
    "keyword_key_result = []\n",
    "\n",
    "\n",
    "for index, bigram in enumerate(doc_bigram_embeddings):\n",
    "    bigram_result = []\n",
    "    key_result=[]\n",
    "    \n",
    "    for i in range(len(bigram)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([bigram[i]],[keyword_embedding[j]])\n",
    "            if distances[0][0] > 0.75:\n",
    "                bigram_result.append(doc_bigram_keywords[index][i])\n",
    "                key_result.append(keyword[j])\n",
    "#         print(bigram_result)\n",
    "#         print(key_result)\n",
    "    bigram_key_result.append(bigram_result)\n",
    "    keyword_key_result.append(key_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
