{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "13272ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 진행 위한 준비\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#우리가 사용할 모델\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "#성능은 조금 안좋지만 빠른 모델\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#문서 전처리 함수\n",
    "def preprocess(df_add):\n",
    "    doc_list = []\n",
    "    for doc in df_add:\n",
    "        #구두점 제거\n",
    "        doc1 = \"\".join([i for i in doc if i not in string.punctuation]).strip()\n",
    "\n",
    "        #숫자 제거\n",
    "        doc2 = \"\".join([i for i in doc1 if not i.isdigit()])\n",
    "\n",
    "        #월 제거\n",
    "        month = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august',\n",
    "                'september', 'october', 'november', 'december', 'jan', 'feb', 'mar', 'apr',\n",
    "                 'may', 'jun','jul', 'aug', 'sep', 'oct', 'nov', 'dec']   \n",
    "        \n",
    "        doc3 = \" \".join([i for i in doc2.split() if i not in month])\n",
    "        \n",
    "        #자체 stopword - 나라별로 생성한 stopword 사용\n",
    "        stopword = [\"australian\", \"australia\" ,\"duty\", \"abfgovauimportingexportingand\", \"manufacturingimportinghowtoimportdisposingunenteredabandonedgoods\", \n",
    "           \"declare\", \"consigment\", \"sorted\", \"license\",\"goods\", \"products\", \"quota\", \"ii\", \"russia\", \"httpswwwabfgovauimporting\", \"customs\",\n",
    "                   \"indexation\", \"working\", \"available\", \"subheadings\", \"cpi\", \"wwwabfgovau\", \"tariff\", \"office\", \"rates\", \"spirits\", \"rules\", \"blue\" ]\n",
    "\n",
    "        doc4 = \" \".join([i for i in doc3.split() if i not in stopword])\n",
    "        doc_list.append(doc4)\n",
    "    \n",
    "    return doc_list\n",
    "\n",
    "#문서 바이그램 단위로 나누는 함수 + nltk 제공하는 불용어 제거\n",
    "def bigram(doc_list):\n",
    "    n_gram_range = (2, 2)\n",
    "    stop_words = \"english\"\n",
    "\n",
    "    candidate_list = []\n",
    "    for doc in doc_list:\n",
    "        count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n",
    "        candidate = count.get_feature_names_out()\n",
    "        candidate_list.append(candidate)\n",
    "    \n",
    "    return candidate_list\n",
    "\n",
    "#전처리 문서와 바이그램 embedding 후 유사도 높은 30개 키워드 추출 함수\n",
    "def bigram_embedding(doc_list, candidate_list):\n",
    "    bigram_keywords = []\n",
    "    top_n = 30\n",
    "\n",
    "    for i in range(len(doc_list)):\n",
    "        doc_embeddings = model.encode([doc_list[i]])\n",
    "        candidate_embeddings = model.encode(candidate_list[i])\n",
    "        distances = cosine_similarity(doc_embeddings, candidate_embeddings)\n",
    "        bigram_keywords.append([candidate_list[i][index] for index in distances.argsort()[0][-top_n:]])\n",
    "        \n",
    "    return bigram_keywords\n",
    "\n",
    "\n",
    "#추출 키워드 embedding 함수\n",
    "def keyword_embedding(bigram_keywords):\n",
    "    bigram_embeddings = []\n",
    "    for i in range(len(doc_list)):\n",
    "        bigram_embedding = []\n",
    "        for keyword in bigram_keywords[i]:\n",
    "            bigram_embedding.append(model.encode(keyword))\n",
    "        bigram_embeddings.append(bigram_embedding)\n",
    "    \n",
    "    return bigram_embeddings\n",
    "\n",
    "#선정 키워드(단어)와 embedding 값 불러오기\n",
    "def get_keyword():\n",
    "    df_keyword = pd.read_csv(\"호주_키워드_HS_KSIC(description 추가).csv\", index_col = False)\n",
    "    keyword = list(df_keyword[\"번역\"])\n",
    "    keyword_embeddings = []\n",
    "\n",
    "    for ele in keyword:\n",
    "        keyword_embeddings.append(model.encode(ele))\n",
    "    \n",
    "    return keyword, keyword_embeddings\n",
    "\n",
    "\n",
    "#추출 키워드와 선정 키워드 유사도 비교 - 유사도는 나라별로 조정\n",
    "def similarity_test(bigram_embeddings, bigram_keywords, keyword_embeddings, keyword):\n",
    "    bigram_result = []\n",
    "    keyword_result = []\n",
    "    cosine_result = []\n",
    "    for index, bigram in enumerate(bigram_embeddings):\n",
    "\n",
    "        b_result = []\n",
    "        k_result = []\n",
    "        c_result = []\n",
    "\n",
    "        for i in range(len(bigram)): \n",
    "            for j in range(len(keyword_embeddings)): \n",
    "                distances = cosine_similarity([bigram[i]],[keyword_embeddings[j]]) #유사도 비교\n",
    "                if distances[0][0] > 0.5:\n",
    "                    b_result.append(bigram_keywords[index][i])\n",
    "                    k_result.append(keyword[j])\n",
    "                    c_result.append(str(round(float(distances),3)))\n",
    "\n",
    "        bigram_result.append(b_result)\n",
    "        keyword_result.append(k_result)\n",
    "        cosine_result.append(c_result)\n",
    "        \n",
    "    return bigram_result, keyword_result, cosine_result\n",
    "\n",
    "#유사도 높은 순으로 df 만들기, 키워드는 최대 5개만 보여줄 예정\n",
    "def make_df(bigram_result, keyword_result, cosine_result):\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "    bigram_list = []\n",
    "    keyword_list = []\n",
    "    distance = []\n",
    "\n",
    "    for i in range(len(df_add)):\n",
    "        B, K, D = [], [], []\n",
    "        b_result,k_result, d_result = \"\", \"\", \"\"\n",
    "        df_check = pd.DataFrame()\n",
    "        df_check['bigram'] = pd.Series(bigram_result[i])\n",
    "        df_check['keyword'] = pd.Series(keyword_result[i])\n",
    "        df_check['distance'] = pd.Series(cosine_result[i])\n",
    "\n",
    "        df_check = df_check.sort_values(by=\"distance\", ascending=False)\n",
    "        \n",
    "        #키워드가 5개보다 많으면 상위 5개만\n",
    "        if len(df_check['bigram']) > 5:\n",
    "            B = df_check['bigram'].tolist()[:5]\n",
    "            K = df_check['keyword'].tolist()[:5]\n",
    "            D = df_check['distance'].tolist()[:5]\n",
    "        #키워드가 5개보다 적으면 전체 보여주기\n",
    "        else:\n",
    "            B = df_check['bigram'].tolist()\n",
    "            K = df_check['keyword'].tolist()\n",
    "            D = df_check['distance'].tolist()\n",
    "\n",
    "\n",
    "        \n",
    "        for b in B:\n",
    "            b_result = b_result + \"/\" + b\n",
    "        for k in K:\n",
    "            k_result = k_result + \"/\" + k\n",
    "        for d in D:\n",
    "            d_result = d_result + \"/\" + d\n",
    "\n",
    "\n",
    "        bigram_list.append(b_result[1:])\n",
    "        keyword_list.append(k_result[1:])\n",
    "        distance.append(d_result[1:])\n",
    "\n",
    "        del df_check\n",
    "\n",
    "    df_final['bigram'] = bigram_list\n",
    "    df_final['keyword'] = keyword_list\n",
    "    df_final['distance'] = distance\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e2d1659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드 뽑은 파일 df로 불러오기\n",
    "df = pd.read_csv(\"___________.csv\")\n",
    "\n",
    "#제목 + 본문 = 문서\n",
    "df_title = list(df['title'])\n",
    "df_text = list(df['text'])\n",
    "df_add = []\n",
    "\n",
    "#제목 + 본문을 하나의 문서로 고려하기 때문에 합치는 작업\n",
    "for i in range(len(df)):\n",
    "    df_add.append(df_title[i].lower()+\"\"+df_text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "350681e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 진행할 문서 개수 지정 - 전체를 돌릴 예정이라면 생략\n",
    "# df_add = df_add[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bd7224de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 코드 - 자체 stopword 생성 위해 테스트 진행하는 경우 아래 과정 따로 진행하는게 더 빠름\n",
    "\n",
    "#문서 전처리 진행\n",
    "doc_list = preprocess(df_add)\n",
    "\n",
    "#문서에서 바이그램 추출\n",
    "candidate_list = bigram(doc_list)\n",
    "\n",
    "#전처리 문서와 바이그램 유사도 비교 후 top 30 바이그램 선정\n",
    "bigram_keywords = bigram_embedding(doc_list, candidate_list) \n",
    "\n",
    "#top 30 바이그램 embedding 진행\n",
    "bigram_embeddings = keyword_embedding(bigram_keywords) \n",
    "\n",
    "#선정 키워드(단어) 불러오기\n",
    "keyword, keyword_embeddings = get_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4245eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유사도 검사\n",
    "bigram_result, keyword_result, cosine_result = similarity_test(bigram_embeddings, bigram_keywords, keyword_embeddings, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d219ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\water\\AppData\\Local\\Temp\\ipykernel_7508\\3539590694.py:139: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_check['bigram'] = pd.Series(bigram_result[i])\n",
      "C:\\Users\\water\\AppData\\Local\\Temp\\ipykernel_7508\\3539590694.py:140: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_check['keyword'] = pd.Series(keyword_result[i])\n",
      "C:\\Users\\water\\AppData\\Local\\Temp\\ipykernel_7508\\3539590694.py:141: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_check['distance'] = pd.Series(cosine_result[i])\n"
     ]
    }
   ],
   "source": [
    "#유사도 큰 순으로 정렬하는 df 생성\n",
    "\n",
    "#합치려고 하는 파일 df로 불러오기\n",
    "df1 = pd.read_csv(\"_______________.csv\", index_col = False)\n",
    "\n",
    "#키워드 df 생성\n",
    "df2 = make_df(bigram_result, keyword_result, cosine_result)\n",
    "\n",
    "#합친 df 생성\n",
    "df3 = pd.concat([df1,df2],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일 만들기 전 df 확인 - 필요 없다면 생략\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a07f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#합친 df 파일로 만들기 - 필요한 제목 입력\n",
    "df3.to_csv('__________.csv', mode='w', encoding='utf-8-sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f46f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
