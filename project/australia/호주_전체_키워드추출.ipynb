{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0d6fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  Indexation of customs duty rates on excise-equivalent goods on 1 August 2022\n",
      "본문 :   australian notice no. 2022/35 indexation of duty rates on excise-equivalent goods on 1 august 2022 \n",
      "문서 :  Indexation of customs duty rates on excise-equivalent goods on 1 August 2022 australian notice no. 2022/35 indexation of duty rates on excise-equivalent goods on 1 august 2022 this notice sets out the new duty rates for certain excise-equivalent goods, including spirits, beers and fuel products, operative from 1 august 2022. section 19 of the tariff act 1995 (customs tariff act) provides for duty rates for certain excise-equivalent goods to be indexed biannually, in february and august, to the consumer price index (cpi). the new rates are determined by the application of an indexation factor. this indexation factor is calculated by dividing the most recent june or december quarter cpi number by the previous highest june or december quarter cpi number occurring after the june 1983 quarter. the december 2021 quarter cpi figure (121.3) will be used to determine the indexation factor for the duty rate increase applied on 1 august 2022, as it is higher than the previously used june 2021 quarter cpi figure (refer to acn 2022/05). on 27 july 2022, the australian bureau of statistics released the june 2022 quarter cpi figure (126.1). the figures used to calculate the indexation factor for august 2022 are set out in the table below: most recent cpi number highest previous june or december quarter june quarter 2022 december quarter 2021 indexation factor 126.1 121.3 1.040 as the indexation factor for august 2022 (1.040) is greater than one, duty rates for certain excise-equivalent goods, in schedule 3 of the tariff, will increase by the application of this factor. the rates of duty for excise-equivalent goods, operative from 1 august 2022, are set out in table 1 below and supersede the rates outlined in australian notice 2022/05. the rates referenced above also apply to goods subject to indexation in:  schedule 4a (singaporean originating goods)  schedule 5 (us originating goods)  schedule 6 (thai originating goods)  schedule 6a (peruvian originating goods)  schedule 7 (chilean originating goods) australia’s service  schedule 8 (asean-australia-new zealand originating goods)  schedule 8a (pacific island originating goods)  schedule 8b (trans-pacific partnership originating goods)  schedule 9 (malaysian originating goods)  schedule 9a (indonesian originating goods)  schedule 10 (korean originating goods)  schedule 11 (japanese originating goods)  schedule 12 (chinese originating goods)  schedule 13 (hong kong originating goods), and  schedule 14 (regional comprehensive economic partnership originating goods) in the tariff act. the australian border force (abf) will arrange for the publication of a notice of substituted rates of duty for excise-equivalent goods (no. 3) 2022 in the gazette. the australian taxation office (ato) will make equivalent changes to the rates of duty on goods subject to excise. further information can be found on the ato website via the following links: ato.gov.au/alcoholexciserates and ato.gov.au/fuelexciserates. fuel duty rates – 1 august 2022 to 28 september 2022 the indexation arrangements outlined above apply to all tariff subheadings listed in section 19aac, including those that have been temporarily reduced consistent with the provisions of the tariff amendment (cost of living support) act 2022. the excise-equivalent duty rates outlined in the last four rows of table 1 apply for the period 1 august 2022 to 28 september 2022. an australian notice will be published in september outlining the rates that will commence on 29 september 2022. please direct any inquiries concerning these matters to the following contacts: for duty rates for excise duty rates director trade and tariff policy australian border force ph: (02) 6264 2143 director indirect tax, revenue performance australian taxation office ph: (02) 6216 1397 changes to the online tariff available on www.abf.gov.au, to reflect the new rates, will be available on commencement of the rates. relevant revised tariff working pages are at attachment a.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#df : 스크래핑한 호주 문서\n",
    "df = pd.read_csv(\"호주_세관_v2(new20).csv\")\n",
    "\n",
    "df_title = list(df['title'])\n",
    "df_text = list(df['text'])\n",
    "df_add = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df_add.append(df_title[i]+\"\"+df_text[i])\n",
    "\n",
    "print(\"제목 : \", df_title[0][:100])\n",
    "print(\"본문 : \", df_text[0][:100])\n",
    "print(\"문서 : \", df_add[0])\n",
    "\n",
    "#df_keyword : 선정한 호주 키워드 101개\n",
    "df_keyword = pd.read_csv(\"호주_번역_100.csv\", index_col = False)\n",
    "# print(len(df_keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b6a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# SentenceTransformer : 모델 훈련 위한 라이브러리\n",
    "# 'distiluse-base-multilingual-cased-v1' : 사용할 모델\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba8bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "#keyword : 불러온 호주 키워드 중 번역 Column 추출\n",
    "keyword = list(df_keyword[\"번역\"])\n",
    "print(len(keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a32fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "#키워드 벡터화\n",
    "keyword_embedding = []\n",
    "\n",
    "for ele in keyword:\n",
    "    keyword_embedding.append(model.encode(ele))\n",
    "\n",
    "print(len(keyword_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d419c15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번 문서 진행 중\n",
      "1 번 문서 진행 중\n",
      "2 번 문서 진행 중\n",
      "3 번 문서 진행 중\n",
      "4 번 문서 진행 중\n",
      "5 번 문서 진행 중\n",
      "6 번 문서 진행 중\n",
      "7 번 문서 진행 중\n",
      "8 번 문서 진행 중\n",
      "9 번 문서 진행 중\n",
      "10 번 문서 진행 중\n",
      "11 번 문서 진행 중\n",
      "12 번 문서 진행 중\n",
      "13 번 문서 진행 중\n",
      "14 번 문서 진행 중\n",
      "15 번 문서 진행 중\n",
      "16 번 문서 진행 중\n",
      "17 번 문서 진행 중\n",
      "18 번 문서 진행 중\n",
      "19 번 문서 진행 중\n",
      "20 번 문서 진행 중\n",
      "21 번 문서 진행 중\n",
      "22 번 문서 진행 중\n",
      "23 번 문서 진행 중\n",
      "24 번 문서 진행 중\n",
      "25 번 문서 진행 중\n",
      "26 번 문서 진행 중\n",
      "27 번 문서 진행 중\n",
      "28 번 문서 진행 중\n",
      "29 번 문서 진행 중\n"
     ]
    }
   ],
   "source": [
    "#호주 문서 10개 embedding\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "doc_embedding = []\n",
    "doc_words = []\n",
    "cnt = 0\n",
    "\n",
    "for doc in df_add:\n",
    "    result = []\n",
    "    sentence = ''\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    doc = doc.replace(\"\\n\", \"\").strip()\n",
    "\n",
    "\n",
    "    word_tokens = pos_tag(word_tokenize(doc))\n",
    "\n",
    "    word_tokens = [t[0] for t in word_tokens if t[1] == \"NN\" and len(t[0]) > 2]\n",
    "    for w in word_tokens:  \n",
    "        if w not in stop_words:\n",
    "            result.append(w)\n",
    "    result = [word.lower() for word in result]\n",
    "    doc_words.append(result)\n",
    "    doc_embedding.append(model.encode(result))\n",
    "    \n",
    "    #카운트 추가\n",
    "    print(cnt, \"번 문서 진행 중\")\n",
    "    cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9794453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{'car'}\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{'plastic'}\n",
      "set()\n",
      "{'car'}\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "{'cheese'}\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "#키워드와 문서 유사도 비교 0.9\n",
    "doc_keywords_9 = []\n",
    "for index, doc in enumerate(doc_embedding):\n",
    "    final_result = []\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([doc[i]], [keyword_embedding[j]])\n",
    "            if distances[0][0]>0.9:\n",
    "                final_result.append(doc_words[index][i])\n",
    "# distances = cosine_similarity([doc_embedding[0]], candidate_embeddings)\n",
    "    print(set(final_result))\n",
    "    doc_keywords_9.append(set(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cbda2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드와 문서 유사도 비교 0.8\n",
    "doc_keywords_8 = []\n",
    "for index, doc in enumerate(doc_embedding):\n",
    "    final_result = []\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([doc[i]], [keyword_embedding[j]])\n",
    "            if distances[0][0]>0.8:\n",
    "                final_result.append(doc_words[index][i])\n",
    "    doc_keywords_8.append(set(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02fde8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#키워드와 문서 유사도 비교 0.75\n",
    "doc_keywords_75 = []\n",
    "for index, doc in enumerate(doc_embedding):\n",
    "    final_result = []\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(keyword_embedding)):\n",
    "            distances = cosine_similarity([doc[i]], [keyword_embedding[j]])\n",
    "            if distances[0][0]>0.75:\n",
    "                final_result.append(doc_words[index][i])\n",
    "    doc_keywords_75.append(set(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac9e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine 0.9</th>\n",
       "      <th>cosine 0.8</th>\n",
       "      <th>cosine 0.75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{fuel}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{car}</td>\n",
       "      <td>{measure, car}</td>\n",
       "      <td>{measure, car, fuel}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{plastic}</td>\n",
       "      <td>{measure, plastic}</td>\n",
       "      <td>{measure, plastic, fuel}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{car}</td>\n",
       "      <td>{car}</td>\n",
       "      <td>{car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{}</td>\n",
       "      <td>{measure}</td>\n",
       "      <td>{measure}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{cheese}</td>\n",
       "      <td>{cheese, curd}</td>\n",
       "      <td>{cheese, curd}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{litre, fuel}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{}</td>\n",
       "      <td>{ricin}</td>\n",
       "      <td>{ricin}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cosine 0.9          cosine 0.8               cosine 0.75\n",
       "0          {}                  {}                    {fuel}\n",
       "1       {car}      {measure, car}      {measure, car, fuel}\n",
       "2          {}                  {}                        {}\n",
       "3          {}                  {}                        {}\n",
       "4          {}                  {}                        {}\n",
       "5          {}                  {}                        {}\n",
       "6          {}                  {}                        {}\n",
       "7          {}                  {}                        {}\n",
       "8   {plastic}  {measure, plastic}  {measure, plastic, fuel}\n",
       "9          {}                  {}                        {}\n",
       "10      {car}               {car}                     {car}\n",
       "11         {}                  {}                        {}\n",
       "12         {}                  {}                        {}\n",
       "13         {}                  {}                        {}\n",
       "14         {}           {measure}                 {measure}\n",
       "15   {cheese}      {cheese, curd}            {cheese, curd}\n",
       "16         {}                  {}                        {}\n",
       "17         {}                  {}                        {}\n",
       "18         {}                  {}             {litre, fuel}\n",
       "19         {}             {ricin}                   {ricin}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = pd.DataFrame()\n",
    "df_check['cosine 0.9'] = doc_keywords_9\n",
    "df_check['cosine 0.8'] = doc_keywords_8\n",
    "df_check['cosine 0.75'] = doc_keywords_75\n",
    "\n",
    "df_check.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cosine 0.9'] = doc_keywords_9\n",
    "df['cosine 0.8'] = doc_keywords_8\n",
    "df['cosine 0.75'] = doc_keywords_75\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c294f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"호주_세관_최근10_유사도, 번역 추가.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
